# Source: https://github.com/hila-chefer/Transformer-Explainability

# Imports
import numpy as np
from numpy import *

# PyTorch Imports
import torch



# Function: Compute rollout between attention layers
def compute_roll